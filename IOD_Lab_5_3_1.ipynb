{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XebDJ3UnS3n3"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e_-HjrL6S3n5"
   },
   "source": [
    "# Lab 5.3.1 \n",
    "# *Support Vector Machines*\n",
    "\n",
    "SVMs use linear algebra to find an (n-1)-dimensional boundary that separates classes within an n-dimensional space. In practical terms, this technique provides a conceptually simple way to predict class membership from a set of features. \n",
    "\n",
    "The standard (linear) SVM is immediately applicable to linear classification problems. Furthermore, by applying transformations to the feature space it is possible to tackle nonlinear classificaiton problems. These transforms are called *kernels*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azVVNUxHYKej"
   },
   "source": [
    "### 1. Load Data\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    "Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1) ID number 2) Diagnosis (M = malignant, B = benign) 3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter) b) texture (standard deviation of gray-scale values) c) perimeter d) area e) smoothness (local variation in radius lengths) f) compactness (perimeter^2 / area - 1.0) g) concavity (severity of concave portions of the contour) h) concave points (number of concave portions of the contour) i) symmetry j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n",
    "\n",
    "All feature values are recoded with four significant digits.\n",
    "\n",
    "Missing attribute values: none\n",
    "\n",
    "Class distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:13:16.458182Z",
     "start_time": "2019-05-09T05:13:16.454244Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "aICmn_7xYKek"
   },
   "outputs": [],
   "source": [
    "breast_cancer_csv = 'breast-cancer-wisconsin-data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FPRqG96QYKen"
   },
   "source": [
    "### 2. EDA \n",
    "\n",
    "- Explore dataset. Clean data (if required)\n",
    "- Find features to predict class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(breast_cancer_csv)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['diagnosis'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B    357\n",
      "M    212\n",
      "Name: diagnosis, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['diagnosis'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['diagnosis'] = data['diagnosis'].replace({'B': 0, 'M': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    int64  \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(2)\n",
      "memory usage: 146.8 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Omwx5vVbYKeo"
   },
   "source": [
    "### 3. Logistic Regression Model\n",
    "\n",
    "#### 3.1 Use Logistic Regression\n",
    "\n",
    "Use Logistic Regression and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Define Target, Predictors\n",
    "- Train-Test Split\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "564    1\n",
       "565    1\n",
       "566    1\n",
       "567    1\n",
       "568    0\n",
       "Name: diagnosis, Length: 569, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target\n",
    "y = data['diagnosis']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302        17.99         10.38          122.80     1001.0   \n",
       "1      842517        20.57         17.77          132.90     1326.0   \n",
       "2    84300903        19.69         21.25          130.00     1203.0   \n",
       "3    84348301        11.42         20.38           77.58      386.1   \n",
       "4    84358402        20.29         14.34          135.10     1297.0   \n",
       "..        ...          ...           ...             ...        ...   \n",
       "564    926424        21.56         22.39          142.00     1479.0   \n",
       "565    926682        20.13         28.25          131.20     1261.0   \n",
       "566    926954        16.60         28.08          108.30      858.1   \n",
       "567    927241        20.60         29.33          140.10     1265.0   \n",
       "568     92751         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictors\n",
    "X = data.drop(columns=['diagnosis', 'Unnamed: 32'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE for imbalanced dataset\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "smt = SMOTE()\n",
    "\n",
    "# how SMOTE works:\n",
    "# print('Before', Counter(y_train))\n",
    "# X_train_smt, y_train_smt = smt.fit_resample(X_train, y_train)\n",
    "# print('After', Counter(y_train_smt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 357, 1: 212})\n"
     ]
    }
   ],
   "source": [
    "# before SMOTE\n",
    "print(Counter(y))\n",
    "\n",
    "# benign (0) has 357 observations\n",
    "# malignant (1) has 212 observations\n",
    "# imbalanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 357, 0: 357})\n"
     ]
    }
   ],
   "source": [
    "X, y = smt.fit_resample(X, y)\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9125874125874126"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine accuracy score, confusion matrix, classification report for that model.\n",
    "LogReg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.70912573e-09, -3.56478133e-03, -6.57072558e-03,\n",
       "        -2.17892510e-02, -3.49765700e-02, -3.57656158e-05,\n",
       "        -1.01714989e-05,  2.24809785e-05,  1.15198670e-05,\n",
       "        -6.89240680e-05, -2.71630762e-05, -1.41155030e-05,\n",
       "        -5.19920857e-04, -8.37602628e-05,  7.00423832e-03,\n",
       "        -3.25166356e-06, -4.64394240e-06, -4.80316137e-06,\n",
       "        -2.17814299e-06, -8.42578528e-06, -1.31298480e-06,\n",
       "        -3.28237433e-03, -8.18619402e-03, -1.98831916e-02,\n",
       "         3.31705670e-02, -4.59574695e-05, -1.61759786e-06,\n",
       "         4.01118466e-05,  8.45173179e-06, -9.45301986e-05,\n",
       "        -2.87329267e-05]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00043961])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8855140186915887"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds = LogReg.predict(X_train)\n",
    "accuracy_score(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136  12]\n",
      " [ 13 125]] \n",
      "\n",
      "[['TN = rly -ve ///' 'FP = actly -ve']\n",
      " ['FN = actly +ve ///' 'TP = rly +ve']]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "preds_test = LogReg.predict(X_test)\n",
    "print(confusion_matrix(y_test, preds_test), \"\\n\")\n",
    "\n",
    "print(np.asarray([['TN = rly -ve ///', 'FP = actly -ve'], ['FN = actly +ve ///', 'TP = rly +ve']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#print(classification_report(y_test, preds_test, labels=['benign', 'malignant']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mogg_w8vYKep"
   },
   "source": [
    "### 4. Support Vector Machine\n",
    "\n",
    "#### 4.1 Use Support Vector Machine\n",
    "\n",
    "Use Support Vector Machine and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Define Target, Predictors\n",
    "- Train-Test Split\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(kernel='rbf', C=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#linear kernel taking too much time, can try:\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5397196261682243"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score\n",
    "\n",
    "preds = clf.predict(X_train)\n",
    "accuracy_score(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 27 121]\n",
      " [ 28 110]] \n",
      "\n",
      "[['TN = rly -ve ///' 'FP = actly -ve']\n",
      " ['FN = actly +ve ///' 'TP = rly +ve']]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "preds_test = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, preds_test), \"\\n\")\n",
    "\n",
    "print(np.asarray([['TN = rly -ve ///', 'FP = actly -ve'], ['FN = actly +ve ///', 'TP = rly +ve']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#print(classification_report(y_test, preds_test, labels=['benign', 'malignant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fdzQkTb7YKeq"
   },
   "source": [
    "### 5. Naive Bayes\n",
    "#### 5.1 Use Naive Bayes\n",
    "\n",
    "Use Naive Bayes and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Define Target, Predictors\n",
    "- Train-Test Split\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "Gaussian = GaussianNB()\n",
    "Gaussian.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5397196261682243"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score\n",
    "\n",
    "preds = clf.predict(X_train)\n",
    "accuracy_score(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 27 121]\n",
      " [ 28 110]] \n",
      "\n",
      "[['TN = rly -ve ///' 'FP = actly -ve']\n",
      " ['FN = actly +ve ///' 'TP = rly +ve']]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "preds_test = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, preds_test), \"\\n\")\n",
    "\n",
    "print(np.asarray([['TN = rly -ve ///', 'FP = actly -ve'], ['FN = actly +ve ///', 'TP = rly +ve']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#print(classification_report(y_test, preds_test, labels=['benign', 'malignant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VoGxthaeYKer"
   },
   "source": [
    "### 6 Gridsearch optimal parameters for all three models.\n",
    "\n",
    "Is there any difference between accuracy score of Logistic Regression and SVM? Use grid serach to find optimal parameter for both these models.\n",
    "\n",
    "> Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments to the constructor of the estimator classes. Typical examples include C, kernel and gamma for Support Vector Classifier, alpha for Lasso, etc.\n",
    "\n",
    "> It is possible and recommended to search the hyper-parameter space for the best cross validation score.\n",
    "\n",
    "> https://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
    "\n",
    "**Note:** It'll take time to execute this. After running the cell, wait for result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UeqrbsyNYKes"
   },
   "source": [
    "#### 6.1 Find Best Estimator For Logistic Regression \n",
    "\n",
    "Find out how these parameters effect model. Find out the best estimator, score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:40:29.397881Z",
     "start_time": "2019-05-09T05:40:29.392602Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UkQ9RBQZYKet"
   },
   "outputs": [],
   "source": [
    "logreg_params = {\n",
    "    'penalty': ['l1','l2'],\n",
    "    'C': [1, 10, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [        nan -1.02935276         nan -1.02935276         nan -1.02935276]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Megan Yit\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the train scores are non-finite: [       nan -1.0291306        nan -1.0291306        nan -1.0291306]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "LogReg = LogisticRegression()\n",
    "\n",
    "finder = GridSearchCV(estimator=LogReg,\n",
    "                     param_grid=logreg_params,\n",
    "                     scoring='r2',\n",
    "                     n_jobs=None,\n",
    "                     return_train_score=True)\n",
    "\n",
    "finder.fit(X_train, y_train)\n",
    "print(finder.best_params_)\n",
    "\n",
    "#outcome C:1, penalty: l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.029352761060078"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.best_score_\n",
    "#-1.029352761060078"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:23:14.036840Z",
     "start_time": "2019-05-09T05:23:14.032847Z"
    },
    "colab_type": "text",
    "id": "ioLgY3bxYKev"
   },
   "source": [
    "#### 6.2 Find Best Estimator For SVM\n",
    "\n",
    "Find out how these parameters effect model. Find out the best estimator, score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:40:31.617090Z",
     "start_time": "2019-05-09T05:40:31.612996Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "vgi61VpWYKew"
   },
   "outputs": [],
   "source": [
    "svc_params = {\n",
    "    'C': [1, 10, 100],\n",
    "    'gamma': [0.001, 0.0001],\n",
    "    'kernel': ['rbf'] #removed 'linear' because it was taking system too long to run\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "\n",
    "finder = GridSearchCV(estimator=clf,\n",
    "                     param_grid=svc_params,\n",
    "                     scoring='r2',\n",
    "                     n_jobs=None,\n",
    "                     return_train_score=True)\n",
    "\n",
    "finder.fit(X_train, y_train)\n",
    "print(finder.best_params_)\n",
    "\n",
    "#outcome C:10, gamma:0.001, kernel:rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5614491483181215"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.best_score_\n",
    "#-0.5614491483181215"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:23:59.157703Z",
     "start_time": "2019-05-09T05:23:59.153713Z"
    },
    "colab_type": "text",
    "id": "HrS04DfuYKez"
   },
   "source": [
    "#### 6.3 Plot the ROC curve for the SVM, Logistic Regressions and Naive Bayes on the same plot\n",
    "\n",
    "Find out which model performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:28:56.671590Z",
     "start_time": "2019-05-09T05:28:56.421258Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "q9TBM2axYKe0",
    "outputId": "8f525757-6f7f-4a8b-d154-235ae82cfdf6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = [{'label': 'Logistic Regression',\n",
    "          'model': LogisticRegression(penalty='l2', C=1.0)},\n",
    "         {'label': 'SVM',\n",
    "         'model': svm.SVC(C=10, gamma=0.0001, kernel='rbf', probability=True)},\n",
    "         {'label': 'Naive Bayes',\n",
    "         'model': GaussianNB()}]\n",
    "\n",
    "plt.figure(figsize=[8,8])\n",
    "\n",
    "colors = ['r', 'g', 'darkorange']\n",
    "\n",
    "for m, c in zip(models, colors):\n",
    "    \n",
    "    model = m['model'] #selects model at each iteration\n",
    "    label=m['label']\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    y_score = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "    \n",
    "    plt.plot(fpr, tpr, color=c, lw=2, label=\"model = %s\" %label)\n",
    "             \n",
    "plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Receiver Operating Characteristic: M', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WrSrz3AAYKe3"
   },
   "source": [
    "### 7. [BONUS] Learning Curve\n",
    "\n",
    "A learning curve shows the validation and training score of an estimator for varying numbers of training samples. It is a tool to find out how much we benefit from adding more training data and whether the estimator suffers more from a variance error or a bias error. If both the validation score and the training score converge to a value that is too low with increasing size of the training set, we will not benefit much from more training data.\n",
    "\n",
    "Plot \"learning curves\" for the best models of each. This is a great way see how training/testing size affects the scores. Look at the documentation for how to use this function in sklearn.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/learning_curve.html#learning-curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:22:19.657638Z",
     "start_time": "2019-05-09T05:22:19.653657Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3Zleg5E-YKe4"
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE8SgkpSYKe7"
   },
   "source": [
    "**References**\n",
    "\n",
    "[Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/downloads/breast-cancer-wisconsin-data.zip/2)\n",
    "\n",
    "[Validation curves: plotting scores to evaluate models](https://scikit-learn.org/stable/modules/learning_curve.html#learning-curves)\n",
    "\n",
    "[In-Depth: Support Vector Machines](https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html)\n",
    "\n",
    "[Understanding Support Vector Machine algorithm from examples (along with code)](https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/)\n",
    "\n",
    "[Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > Â© 2021 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IOD_Lab_5_3_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
